# SpeechForms - Voice-Enabled Form Builder

Create intelligent forms where users can speak their responses instead of typing. Powered by OpenAI's Whisper speech-to-text technology for seamless data collection.

## ğŸš€ Features

- **Voice-First Experience**: Users can speak their responses naturally
- **Flexible Form Builder**: Create custom forms with various field types
- **AI-Powered Accuracy**: Powered by OpenAI's Whisper for industry-leading speech recognition
- **Real-time Transcription**: Instant speech-to-text conversion
- **Modern UI**: Beautiful, responsive design built with Next.js and Tailwind CSS
- **Form Management**: Create, edit, duplicate, and manage forms
- **Response Collection**: Store and view form responses
- **Demo Mode**: Try the functionality without creating forms

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 15, React 19, Tailwind CSS
- **Icons**: Lucide React
- **Animations**: Framer Motion
- **Notifications**: React Hot Toast
- **Speech-to-Text**: OpenAI Whisper API
- **Storage**: localStorage (easily replaceable with database)

## ğŸ“‹ Prerequisites

- Node.js 18+ installed
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))

## ğŸš€ Getting Started

1. **Clone and install dependencies**:
```bash
git clone <your-repo-url>
cd speech-form
npm install
```

2. **Set up environment variables**:
Create a `.env.local` file in the root directory:
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

3. **Run the development server**:
```bash
npm run dev
```

4. **Open your browser**:
Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“± How to Use

### Creating Forms
1. Go to the Dashboard (`/dashboard`)
2. Click "Create Form"
3. Add form title and description
4. Add fields using the sidebar (text, email, phone, date, multiple choice, etc.)
5. Configure field labels, placeholders, and requirements
6. Save your form

### Filling Forms
1. Share the form URL with users
2. Users can either type responses OR use voice input
3. Click the microphone button to start recording
4. Speak clearly and click stop when done
5. Speech is automatically transcribed to text
6. Submit the completed form

### Managing Forms
- **View Forms**: See all your forms in the dashboard
- **Edit Forms**: Modify existing forms
- **Duplicate Forms**: Copy forms to create variants
- **Delete Forms**: Remove unwanted forms
- **Copy Links**: Share form URLs easily
- **View Responses**: Check submitted responses

## ğŸ¯ Voice Input Tips

For best speech recognition results:
- Speak clearly and at a normal pace
- Use a quiet environment
- Say "period" or "comma" for punctuation
- For emails, say "john dot smith at gmail dot com"
- For multiple choice, speak the exact option name
- Click stop when you finish speaking

## ğŸŒŸ Demo

Try the demo at `/demo` to experience voice-enabled forms without creating an account. The demo includes:
- Text input fields
- Email fields with voice recognition
- Multiple choice with smart matching
- Long text areas for detailed responses
- Real-time response preview

## ğŸ”§ API Endpoints

### POST `/api/transcribe`
Transcribes audio to text using OpenAI Whisper.

**Request**: FormData with audio file
**Response**: 
```json
{
  "success": true,
  "text": "transcribed text"
}
```

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ components/          # Reusable components
â”‚   â””â”€â”€ VoiceInput.js   # Voice recording and transcription
â”œâ”€â”€ dashboard/          # Dashboard pages
â”‚   â”œâ”€â”€ page.js        # Forms list
â”‚   â””â”€â”€ create/        # Form builder
â”œâ”€â”€ form/[id]/         # Public form filling
â”œâ”€â”€ demo/              # Demo page
â”œâ”€â”€ api/               # API routes
â”‚   â””â”€â”€ transcribe/    # Speech-to-text endpoint
â”œâ”€â”€ layout.js          # Root layout
â”œâ”€â”€ page.js            # Landing page
â””â”€â”€ globals.css        # Global styles
```

## ğŸ¨ Customization

### Styling
- Built with Tailwind CSS
- Modify `globals.css` for global styles
- Component-level styling in individual files

### Voice Recognition
- Configured for English by default
- Modify the `language` parameter in the transcription API
- Adjust temperature for more/less conservative transcription

### Storage
- Currently uses localStorage
- Easy to replace with database (PostgreSQL, MongoDB, etc.)
- Response format is JSON-ready

## ğŸš€ Deployment

### Vercel (Recommended)
1. Push to GitHub
2. Connect to Vercel
3. Add `OPENAI_API_KEY` environment variable
4. Deploy!

### Other Platforms
- Ensure Node.js 18+ support
- Set environment variables
- Run `npm run build && npm start`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ†˜ Support

If you encounter issues:
1. Check that your OpenAI API key is correctly set
2. Ensure microphone permissions are granted
3. Test in a supported browser (Chrome, Firefox, Safari)
4. Check the browser console for errors

## ğŸ”® Future Enhancements

- [ ] User authentication and accounts
- [ ] Database integration (PostgreSQL/MongoDB)
- [ ] Form analytics and insights
- [ ] Multiple language support
- [ ] Custom themes and branding
- [ ] Export responses to CSV/Excel
- [ ] Webhook integrations
- [ ] Advanced field types (file upload, signatures)
- [ ] Form templates
- [ ] Conditional logic (show/hide fields)

---

Built with â¤ï¸ using Next.js and OpenAI Whisper
